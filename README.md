# ğŸ¤– IA Personnelle Autonome & Locale

SystÃ¨me cognitif autonome, local et incarnÃ©, capable d'interagir avec un humain, d'apprendre Ã  partir de ses Ã©changes, de dÃ©velopper une mÃ©moire Ã©motionnelle, et d'Ã©voluer dans le temps comme une entitÃ© persistante.

## ğŸ¯ CaractÃ©ristiques

- âœ… **100% Local** - Aucun cloud, aucune API externe
- ğŸ§  **MÃ©moire Multi-couches** - Court terme, long terme, vectorielle (FAISS)
- ğŸ§¡ **MÃ©moire Ã‰motionnelle** - Ã‰tats Ã©motionnels pour prioriser et interagir
- ğŸ“š **Apprentissage** - Apprend de chaque interaction et correction
- ğŸ­ **PersonnalitÃ© Ã‰volutive** - Se dÃ©veloppe Ã  partir des expÃ©riences
- ğŸ¤– **IncarnÃ©e** - Interface extensible vers avatar 3D (Unity)

## ğŸ—ï¸ Architecture

```
ai_entity/
â”œâ”€â”€ consciousness/     # Conscience centrale (orchestrateur)
â”œâ”€â”€ emotion/           # SystÃ¨me Ã©motionnel
â”œâ”€â”€ memory/            # MÃ©moire (court/long terme, FAISS)
â”œâ”€â”€ learning/          # Moteur d'apprentissage
â”œâ”€â”€ reasoning/         # Raisonnement et personnalitÃ©
â”œâ”€â”€ llm/              # Interface Ollama (LLM local)
â”œâ”€â”€ embodiment/        # Incarnation (avatar)
â””â”€â”€ interface/         # Interface CLI
```

## ğŸ“‹ PrÃ©requis

1. **Python 3.11+**
2. **Ollama** installÃ© et dÃ©marrÃ©
   - Installation: https://ollama.ai
   - DÃ©marrer: `ollama serve`
   - TÃ©lÃ©charger un modÃ¨le: `ollama pull llama3`

## ğŸš€ Installation

1. Cloner ou tÃ©lÃ©charger ce projet

2. Installer les dÃ©pendances:
```bash
# Sur Windows:
python -m pip install -r requirements.txt
# ou
py -m pip install -r requirements.txt

# Sur Linux/Mac:
pip install -r requirements.txt
```

3. VÃ©rifier qu'Ollama est dÃ©marrÃ©:
```bash
ollama serve
```

4. TÃ©lÃ©charger un modÃ¨le (optionnel, mais recommandÃ©):
```bash
ollama pull llama3
# ou
ollama pull mistral
# ou
ollama pull qwen
```

## ğŸ’» Utilisation

### Mode CLI (Interface en ligne de commande)

Lancer l'IA:
```bash
python main.py
```

### Mode API (Pour Unity)

DÃ©marrer le serveur API pour Unity:
```bash
python main.py --api
# ou
python api_server.py
```

Le serveur dÃ©marre sur `http://localhost:5000`

ğŸ“– **Voir `UNITY_INTEGRATION.md` pour l'intÃ©gration complÃ¨te avec Unity**

### Commandes disponibles

- `talk <message>` - Parler avec l'IA
- `teach <contenu>` - Enseigner quelque chose Ã  l'IA
- `correct <input> | <correction>` - Corriger une rÃ©ponse
- `remember` - Voir les souvenirs rÃ©cents
- `forget <id>` - Oublier un souvenir
- `emotion` - Voir l'Ã©tat Ã©motionnel actuel
- `status` - Voir le statut complet de l'IA
- `avatar` - Afficher l'Ã©tat de l'avatar
- `ingest <fichier>` - IngÃ©rer un document dans la mÃ©moire
- `batch-ingest <dir>` - IngÃ©rer tous les fichiers d'un rÃ©pertoire
- `help` - Afficher l'aide
- `quit` / `exit` - Quitter

### Exemples

```bash
# Parler avec l'IA
talk Bonjour, comment vas-tu ?

# Enseigner quelque chose
teach Python est un langage de programmation interprÃ©tÃ©

# Corriger une rÃ©ponse
correct Python | Python est un langage interprÃ©tÃ© et orientÃ© objet

# Voir l'Ã©tat Ã©motionnel
emotion

# Voir le statut
status

# IngÃ©rer un document
ingest mon_document.txt

# IngÃ©rer tous les fichiers d'un rÃ©pertoire
batch-ingest data/documents
```

## ğŸ§  Fonctionnement

### Cycle Cognitif

1. **Perception** - RÃ©ception du message utilisateur
2. **Ã‰motion** - Analyse et gÃ©nÃ©ration d'Ã©tat Ã©motionnel
3. **MÃ©moire** - RÃ©cupÃ©ration de souvenirs pertinents
4. **Raisonnement** - Construction du prompt avec contexte
5. **RÃ©ponse** - GÃ©nÃ©ration via LLM local
6. **Apprentissage** - Stockage et mise Ã  jour

### MÃ©moire Ã‰motionnelle

L'IA modÃ©lise des Ã©tats Ã©motionnels (pas une simulation humaine) pour:
- Prioriser les souvenirs
- Influencer le ton de rÃ©ponse
- DÃ©velopper la personnalitÃ©
- Mieux interagir

Dimensions Ã©motionnelles:
- **Valence**: Positif / NÃ©gatif
- **Arousal**: Calme / Intense
- **Dominance**: Passif / Actif
- **Confiance**: Confiance envers l'utilisateur
- **CuriositÃ©**: Niveau de curiositÃ©
- **Attachement**: Attachement contextuel

### Apprentissage

L'IA apprend de:
- Chaque interaction conversationnelle
- Enseignements explicites (`teach`)
- Corrections (`correct`)
- Documents ingÃ©rÃ©s (`ingest` ou `batch-ingest`)

ğŸ“š **Pour le fine-tuning et l'intÃ©gration de donnÃ©es en masse**, consultez `FINE_TUNING_GUIDE.md`

## ğŸ“‚ Structure des DonnÃ©es

Les donnÃ©es sont stockÃ©es dans `data/`:
- `memory.db` - Base SQLite (mÃ©tadonnÃ©es)
- `vectors.faiss` - Index FAISS (recherche sÃ©mantique)
- `memories/` - Fichiers de souvenirs
- `emotions/` - Historique Ã©motionnel

## âš™ï¸ Configuration

Modifier `config.py` pour ajuster:
- ModÃ¨le LLM (llama3, mistral, qwen)
- ParamÃ¨tres de mÃ©moire
- Seuils Ã©motionnels
- PersonnalitÃ© par dÃ©faut

## ğŸ”’ SÃ©curitÃ© & ConfidentialitÃ©

- **100% Local** - Aucune donnÃ©e ne quitte votre machine
- **Aucune API externe** - Fonctionne hors ligne
- **DonnÃ©es privÃ©es** - Tous les souvenirs restent locaux

## ğŸ¯ Vision Future

Cette IA peut devenir:
- Un compagnon numÃ©rique personnel
- Une entitÃ© incarnÃ©e dans Unity
- Un cerveau IA persistant cross-projets
- Une IA relationnelle Ã©ducable

## ğŸ“ Notes

- L'IA ne "ressent" rien - elle modÃ©lise des Ã©tats Ã©motionnels pour mieux fonctionner
- Chaque fichier fait â‰¤ 200 lignes pour maintenir la lisibilitÃ©
- Architecture modulaire pour faciliter l'extension
- Code commentÃ© et documentÃ©

## ğŸ› DÃ©pannage

**Ollama non disponible:**
- VÃ©rifier que `ollama serve` est dÃ©marrÃ©
- VÃ©rifier que le modÃ¨le est tÃ©lÃ©chargÃ©: `ollama list`

**Erreurs de mÃ©moire:**
- VÃ©rifier les permissions d'Ã©criture dans `data/`
- VÃ©rifier l'espace disque disponible

**Erreurs d'import:**
- VÃ©rifier que toutes les dÃ©pendances sont installÃ©es: `pip install -r requirements.txt`

## ğŸ“„ Licence

Ce projet est fourni tel quel, pour usage personnel et Ã©ducatif.

---

**DÃ©veloppÃ© avec â¤ï¸ pour crÃ©er une IA vraiment personnelle et locale.**
